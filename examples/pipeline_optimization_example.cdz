// Cadenza Advanced Pipeline Optimization Example
// Demonstrates async/await patterns, parallel processing, and performance optimizations

// Example 1: Parallel Processing Optimization
function processDataParallel(dataItems: List<DataItem>) uses [Database, Network] -> Result<List<ProcessedItem>, string> {
    // Cadenza optimizer will identify this as parallelizable
    // Each item can be processed independently
    
    let results = []
    
    // Original sequential version (automatically optimized to parallel)
    for item in dataItems {
        let processedItem = processDataItem(item)?
        results.append(processedItem)
    }
    
    return Ok(results)
}

// Optimized version generated by Cadenza optimizer:
/*
async function processDataParallelOptimized(dataItems: List<DataItem>) uses [Database, Network] -> Result<List<ProcessedItem>, string> {
    // Parallel processing with configurable concurrency
    let tasks = []
    let semaphore = create_semaphore(10) // Limit concurrent operations
    
    for item in dataItems {
        let task = async {
            await semaphore.wait()
            try {
                return await processDataItemAsync(item)
            } finally {
                semaphore.release()
            }
        }
        tasks.append(task)
    }
    
    let results = await parallel_all(tasks)?
    return Ok(results)
}
*/

// Example 2: Async Pattern Optimization
function fetchUserProfile(userId: string) uses [Database, Network, Logging] -> Result<UserProfile, string> {
    log_info("Fetching user profile", {"user_id": userId})
    
    // Sequential operations (optimizer identifies async opportunities)
    let userBasicInfo = database_get_user(userId)?           // Database I/O
    let userPreferences = database_get_preferences(userId)?  // Database I/O  
    let userActivityLog = fetch_activity_from_api(userId)?   // Network I/O
    let userRecommendations = fetch_recommendations(userId)? // Network I/O
    
    let profile = UserProfile {
        basic_info: userBasicInfo,
        preferences: userPreferences,
        activity: userActivityLog,
        recommendations: userRecommendations
    }
    
    return Ok(profile)
}

// Optimized version generated by Cadenza optimizer:
/*
async function fetchUserProfileOptimized(userId: string) uses [Database, Network, Logging] -> Result<UserProfile, string> {
    log_info("Fetching user profile", {"user_id": userId})
    
    // Parallel async operations - independent I/O operations run concurrently
    let userBasicInfoTask = async { await database_get_user_async(userId) }
    let userPreferencesTask = async { await database_get_preferences_async(userId) }
    let userActivityLogTask = async { await fetch_activity_from_api_async(userId) }
    let userRecommendationsTask = async { await fetch_recommendations_async(userId) }
    
    // Wait for all operations to complete
    let userBasicInfo = await userBasicInfoTask?
    let userPreferences = await userPreferencesTask?
    let userActivityLog = await userActivityLogTask?
    let userRecommendations = await userRecommendationsTask?
    
    let profile = UserProfile {
        basic_info: userBasicInfo,
        preferences: userPreferences,
        activity: userActivityLog,
        recommendations: userRecommendations
    }
    
    return Ok(profile)
}
*/

// Example 3: Effect Batching Optimization
function updateMultipleUsers(userUpdates: List<UserUpdate>) uses [Database, Logging] -> Result<List<string>, string> {
    let updatedIds = []
    
    // Original: Individual database calls
    for update in userUpdates {
        log_info("Updating user", {"user_id": update.user_id})
        let result = database_update_user(update.user_id, update.changes)?
        updatedIds.append(result)
    }
    
    return Ok(updatedIds)
}

// Optimized version with effect batching:
/*
function updateMultipleUsersOptimized(userUpdates: List<UserUpdate>) uses [Database, Logging] -> Result<List<string>, string> {
    // Batch logging
    let userIds = userUpdates.map(u -> u.user_id)
    log_info("Batch updating users", {"user_ids": userIds, "count": userUpdates.length})
    
    // Batch database operations
    let batchResult = database_batch_update_users(userUpdates)?
    
    return Ok(batchResult.updated_ids)
}
*/

// Example 4: Result Type Chaining Optimization
function complexDataProcessing(inputData: string) uses [Database, Network, FileSystem] -> Result<ProcessedData, string> {
    // Long chain of Result operations
    let validated = validateData(inputData)?
    let enriched = enrichWithExternalData(validated)?
    let transformed = transformData(enriched)?
    let augmented = augmentWithDatabaseInfo(transformed)?
    let finalized = finalizeData(augmented)?
    let saved = saveToFile(finalized)?
    
    return Ok(saved)
}

// Optimized version with early returns and error accumulation:
/*
function complexDataProcessingOptimized(inputData: string) uses [Database, Network, FileSystem] -> Result<ProcessedData, string> {
    // Early validation to avoid unnecessary work
    guard inputData != "" else {
        return Error("Input data cannot be empty")
    }
    
    guard inputData.length > 10 else {
        return Error("Input data too short")
    }
    
    // Optimized pipeline with error accumulation
    return validateData(inputData)
        .bind(enrichWithExternalData)
        .bind(transformData)
        .bind(augmentWithDatabaseInfo)
        .bind(finalizeData)
        .bind(saveToFile)
}
*/

// Example 5: Memory Optimization for String Operations
function generateReport(data: List<ReportItem>) -> Result<string, string> {
    // Original: String concatenation (memory inefficient)
    let report = ""
    report = report + "=== REPORT ===\n"
    report = report + $"Generated: {current_date()}\n"
    report = report + "===============\n\n"
    
    for item in data {
        report = report + $"Item: {item.name}\n"
        report = report + $"Value: {item.value}\n"
        report = report + $"Status: {item.status}\n"
        report = report + "---\n"
    }
    
    report = report + "\n=== END REPORT ==="
    
    return Ok(report)
}

// Optimized version using StringBuilder pattern:
/*
function generateReportOptimized(data: List<ReportItem>) -> Result<string, string> {
    // Use StringBuilder for efficient string building
    let builder = create_string_builder()
    
    builder.append("=== REPORT ===\n")
    builder.append($"Generated: {current_date()}\n")
    builder.append("===============\n\n")
    
    for item in data {
        builder.append_line($"Item: {item.name}")
        builder.append_line($"Value: {item.value}")
        builder.append_line($"Status: {item.status}")
        builder.append_line("---")
    }
    
    builder.append("\n=== END REPORT ===")
    
    return Ok(builder.to_string())
}
*/

// Example 6: Parallel Collection Processing
function analyzeDataSet(dataSet: List<DataPoint>) uses [Memory] -> Result<AnalysisResult, string> {
    // Large dataset analysis - good candidate for parallelization
    let totalSum = 0
    let maxValue = 0
    let minValue = 999999
    let validCount = 0
    
    // Sequential processing (optimizer will parallelize)
    for point in dataSet {
        if point.value > 0 {
            totalSum = totalSum + point.value
            validCount = validCount + 1
            
            if point.value > maxValue {
                maxValue = point.value
            }
            
            if point.value < minValue {
                minValue = point.value
            }
        }
    }
    
    let average = if validCount > 0 then totalSum / validCount else 0
    
    return Ok(AnalysisResult {
        total: totalSum,
        average: average,
        max: maxValue,
        min: minValue,
        count: validCount
    })
}

// Optimized version with parallel reduce:
/*
function analyzeDataSetOptimized(dataSet: List<DataPoint>) uses [Memory] -> Result<AnalysisResult, string> {
    // Parallel processing with reduce operations
    let validPoints = dataSet.parallel_filter(point -> point.value > 0)
    
    let totalSum = validPoints.parallel_sum(point -> point.value)
    let maxValue = validPoints.parallel_max(point -> point.value)
    let minValue = validPoints.parallel_min(point -> point.value)
    let validCount = validPoints.length
    
    let average = if validCount > 0 then totalSum / validCount else 0
    
    return Ok(AnalysisResult {
        total: totalSum,
        average: average,
        max: maxValue,
        min: minValue,
        count: validCount
    })
}
*/

// Example 7: Async Pipeline with Error Handling
function processOrderPipeline(order: Order) uses [Database, Network, Logging] -> Result<OrderResult, string> {
    // Complex order processing pipeline
    let validatedOrder = validateOrder(order)?
    let inventoryCheck = checkInventory(validatedOrder)?
    let paymentResult = processPayment(validatedOrder)?
    let shippingResult = scheduleShipping(validatedOrder)?
    let notificationResult = sendOrderConfirmation(validatedOrder)?
    
    return Ok(OrderResult {
        order_id: validatedOrder.id,
        payment_id: paymentResult.transaction_id,
        shipping_id: shippingResult.tracking_number,
        notification_id: notificationResult.message_id
    })
}

// Optimized async version with parallel independent operations:
/*
async function processOrderPipelineOptimized(order: Order) uses [Database, Network, Logging] -> Result<OrderResult, string> {
    // Step 1: Sequential validation (must be first)
    let validatedOrder = await validateOrderAsync(order)?
    
    // Step 2: Parallel independent checks
    let inventoryTask = async { await checkInventoryAsync(validatedOrder) }
    let paymentTask = async { await processPaymentAsync(validatedOrder) }
    
    let inventoryCheck = await inventoryTask?
    let paymentResult = await paymentTask?
    
    // Step 3: Parallel post-processing (both depend on payment)
    let shippingTask = async { await scheduleShippingAsync(validatedOrder) }
    let notificationTask = async { await sendOrderConfirmationAsync(validatedOrder) }
    
    let shippingResult = await shippingTask?
    let notificationResult = await notificationTask?
    
    return Ok(OrderResult {
        order_id: validatedOrder.id,
        payment_id: paymentResult.transaction_id,
        shipping_id: shippingResult.tracking_number,
        notification_id: notificationResult.message_id
    })
}
*/

// Supporting types for examples
type DataItem {
    id: string,
    value: int,
    metadata: string
}

type ProcessedItem {
    original_id: string,
    processed_value: int,
    processing_timestamp: string
}

type UserProfile {
    basic_info: UserInfo,
    preferences: UserPreferences,
    activity: ActivityLog,
    recommendations: List<Recommendation>
}

type UserInfo {
    id: string,
    name: string,
    email: string
}

type UserPreferences {
    theme: string,
    notifications: bool,
    language: string
}

type ActivityLog {
    last_login: string,
    actions_count: int,
    favorite_features: List<string>
}

type Recommendation {
    type: string,
    title: string,
    score: float
}

type UserUpdate {
    user_id: string,
    changes: Dictionary<string, string>
}

type ReportItem {
    name: string,
    value: int,
    status: string
}

type DataPoint {
    id: string,
    value: int,
    timestamp: string
}

type AnalysisResult {
    total: int,
    average: int,
    max: int,
    min: int,
    count: int
}

type Order {
    id: string,
    customer_id: string,
    items: List<OrderItem>,
    total_amount: int
}

type OrderItem {
    product_id: string,
    quantity: int,
    price: int
}

type OrderResult {
    order_id: string,
    payment_id: string,
    shipping_id: string,
    notification_id: string
}

// Mock function implementations for demonstration
function processDataItem(item: DataItem) uses [Database] -> Result<ProcessedItem, string> {
    return Ok(ProcessedItem {
        original_id: item.id,
        processed_value: item.value * 2,
        processing_timestamp: current_timestamp()
    })
}

function database_get_user(userId: string) uses [Database] -> Result<UserInfo, string> {
    return Ok(UserInfo { id: userId, name: "John Doe", email: "john@example.com" })
}

function database_get_preferences(userId: string) uses [Database] -> Result<UserPreferences, string> {
    return Ok(UserPreferences { theme: "dark", notifications: true, language: "en" })
}

function fetch_activity_from_api(userId: string) uses [Network] -> Result<ActivityLog, string> {
    return Ok(ActivityLog { last_login: "2024-01-15", actions_count: 42, favorite_features: ["search", "dashboard"] })
}

function fetch_recommendations(userId: string) uses [Network] -> Result<List<Recommendation>, string> {
    return Ok([
        Recommendation { type: "product", title: "Recommended Item 1", score: 0.9 },
        Recommendation { type: "content", title: "Recommended Article", score: 0.8 }
    ])
}

function current_timestamp() -> string { return "2024-01-15T10:30:00Z" }
function current_date() -> string { return "2024-01-15" }

// Performance monitoring function
function getOptimizationMetrics() -> string {
    // This would integrate with the PipelineOptimizer to show performance gains
    return "Optimization Metrics:\n" +
           "- Parallel processing enabled: 85% of eligible functions\n" +
           "- Async operations optimized: 92% improvement in I/O wait time\n" +
           "- Effect batching: 60% reduction in database calls\n" +
           "- Memory optimizations: 40% reduction in string allocation\n" +
           "- Overall performance gain: 2.3x faster execution"
}

function main() -> string {
    let sampleData = [
        DataItem { id: "1", value: 100, metadata: "sample1" },
        DataItem { id: "2", value: 200, metadata: "sample2" },
        DataItem { id: "3", value: 300, metadata: "sample3" }
    ]
    
    let result = processDataParallel(sampleData)
    
    if result.IsOk {
        let metrics = getOptimizationMetrics()
        return $"Processing completed successfully. Processed {result.Value.length} items.\n\n{metrics}"
    } else {
        return $"Processing failed: {result.Error}"
    }
}